---
layout: post
title: assembly
date: '2021-09-17'
categories: Analysis
tags: bioinformatics
---

_**Objective:**_ 

- Determine if subsampling reads prior to assembly makes a difference for metagneomic assembly statistics, metrics to look at: length of assembly, N50 metrics etc.
- Learn to use SLURM system on the MERCED cluster 

Helful links: 

[getting started](https://github.com/ucmerced/merced-cluster/wiki/Getting-Started)
[rosetta qsub to slurm](https://slurm.schedmd.com/rosetta.pdf)

1. Setting up the work space

Data structure: 

```data/```  data repository for backed up data
```scratch/``` scratch will be cleaned up every 5 weeks; good for jobs etc


typical slurm script: 
```bash
#!/bin/bash  
#SBATCH --mail-user=esogin@ucmerced.edu  
#SBATCH --mail-type=ALL  
#SBATCH --nodes=1  
#SBATCH --ntasks=20
#SBATCH --partition fast.q  
#SBATCH --mem=96G  
#SBATCH --time=0-00:15:00 # 15 minutes  
#SBATCH --output=test.qlog  
#SBATCH --job-name=test
#SBATCH --export=ALL

# This submission file will run a simple set of commands. All stdout will
# be captured in test1.qlog (as specified in the Slurm command --output above).
# This job file uses a shared-memory parallel environment and requests 20
# cores (--ntasks option) on a single node(--nodes option). This job will also run a global #script called
# run. For more info on this script, cat /usr/local/bin/merced_node_print.
#  

whoami

pwd

uptime
hostname
date
```

To submit the job: ```sbatch script```


2. Start  

This scripts will: 
(1) download the sequencing reads from ENA
(2) check the md5sums 
(3) preform basic quality trimming
(4) subsample reads to 5%, 10%, 20%, 40% and 80%
(5) removes raw squecing read files

Tools required: bbtools

```bash
#!/bin/bash 
#SBATCH --mail-user=esogin@ucmerced.edu  
#SBATCH --mail-type=ALL  
#SBATCH --nodes=1  
#SBATCH --ntasks=20
#SBATCH --partition std.q  
#SBATCH --mem=96G  
#SBATCH --time=0-24:00:00 #  
#SBATCH --job-name=start
#SBATCH --export=ALL


##----------01 Download data from ENA/Facilitity--------------##
echo "--------download file--------"

## Study accession  nr. PRJEB35096	
#sample run accession nr:

mkdir /home/esogin/scratch/prj001-comp-gene-chr/01_Data/00_raw/
cd /home/esogin/scratch/prj001-comp-gene-chr/01_Data/00_raw/
i=ERR3624084	
wget -q ftp://ftp.sra.ebi.ac.uk/vol1/fastq/${i:0:6}/00${i:9:10}/$i/$i* 

##----------02 Clean Data --------------##
echo "--------clean data--------"

mkdir /home/esogin/scratch/prj001-comp-gene-chr/01_Data/01_trimmed/
cd /home/esogin/scratch/prj001-comp-gene-chr/01_Data/01_trimmed;

bbduk.sh ref=/home/esogin/data/db/adapters.fa ktrim=l minlength=36 mink=11 hdist=1 in=../00_raw/$i_1.fastq.gz in2=../00_raw/$i_1.fastq.gz out=${i}_ktriml.fq.gz;
bbduk.sh ref=/home/esogin/data/db/adapters.fa ktrim=r trimq=2 qtrim=rl minlength=36 mink=11 hdist=1 in=${i}_ktriml.fq.gz interleaved=t out=${i}_q2_ktrimmed.fq.gz;

rm $i_1.fastq.gz ${i}_ktriml.fq.gz

##----------03 Subsample Data --------------##
echo "--------subsample data--------"

mkdir /home/esogin/scratch/prj001-comp-gene-chr/02_Analysis/01_subsampled -p;
cd /home/esogin/scratch/prj001-comp-gene-chr/02_Analysis/01_subsampled;

reformat.sh in=/home/esogin/prj001-comp-gene-chr/01_Data/02_trimmed/${i}_q2_ktrimmed.fq.gz samplerate=0.1 out=${i}_0.1.fq.gz
reformat.sh in=/home/esogin/prj001-comp-gene-chr/01_Data/02_trimmed/${i}_q2_ktrimmed.fq.gz samplerate=0.2 out=${i}_0.2.fq.gz
reformat.sh in=/home/esogin/prj001-comp-gene-chr/01_Data/02_trimmed/${i}_q2_ktrimmed.fq.gz samplerate=0.4 out=${i}_0.4.fq.gz
reformat.sh in=/home/esogin/prj001-comp-gene-chr/01_Data/02_trimmed/${i}_q2_ktrimmed.fq.gz samplerate=0.8 out=${i}_0.8.fq.gz
reformat.sh in=/home/esogin/prj001-comp-gene-chr/01_Data/02_trimmed/${i}_q2_ktrimmed.fq.gz samplerate=1 out=${i}_1.fq.gz

##----------04 Copy results back to /home/data --------------##
rsync -r /home/esogin/scratch/prj001-comp-gene-chr/ /home/esogin/scratch/prj001-comp-gene-chr/

echo "clean up scratch"

uptime
hostname
date
```








